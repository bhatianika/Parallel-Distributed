**Q1**

#include <mpi.h>
#include <stdio.h>
#include <stdlib.h>
#include <time.h>
#include <math.h>

#define NUM_POINTS 1000000

void estimate_pi(int rank, int size) {
    int local_count = 0;
    int total_count = 0;
    double x, y;
    unsigned int seed = time(NULL) + rank; // Unique seed for each process

    for (int i = 0; i < NUM_POINTS / size; i++) {
        x = (double)rand_r(&seed) / RAND_MAX;
        y = (double)rand_r(&seed) / RAND_MAX;
        if (x * x + y * y <= 1.0) {
            local_count++;
        }
    }

    MPI_Reduce(&local_count, &total_count, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);
    
    if (rank == 0) {
        double pi_estimate = (4.0 * total_count) / NUM_POINTS;
        printf("Estimated Pi = %lf\n", pi_estimate);
    }
}

int main(int argc, char** argv) {
    MPI_Init(&argc, &argv);
    int rank, size;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);

    estimate_pi(rank, size);
    
    MPI_Finalize();
    return 0;
}


**Q2**

#include <mpi.h>
#include <stdio.h>
#include <stdlib.h>
#include <time.h>

#define N 70

double A[N][N], B[N][N], C[N][N];

void initialize_matrices() {
    for (int i = 0; i < N; i++) {
        for (int j = 0; j < N; j++) {
            A[i][j] = rand() % 10;
            B[i][j] = rand() % 10;
            C[i][j] = 0.0;
        }
    }
}

void matrix_multiply(int rank, int size) {
    int rows_per_process = N / size;
    int start_row = rank * rows_per_process;
    int end_row = (rank == size - 1) ? N : start_row + rows_per_process;

    for (int i = start_row; i < end_row; i++) {
        for (int j = 0; j < N; j++) {
            for (int k = 0; k < N; k++) {
                C[i][j] += A[i][k] * B[k][j];
            }
        }
    }

    MPI_Gather(C[start_row], rows_per_process * N, MPI_DOUBLE, C, rows_per_process * N, MPI_DOUBLE, 0, MPI_COMM_WORLD);
}

int main(int argc, char** argv) {
    MPI_Init(&argc, &argv);
    int rank, size;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);

    if (rank == 0) {
        initialize_matrices();
    }

    MPI_Bcast(A, N * N, MPI_DOUBLE, 0, MPI_COMM_WORLD);
    MPI_Bcast(B, N * N, MPI_DOUBLE, 0, MPI_COMM_WORLD);

    double start_time = MPI_Wtime();
    matrix_multiply(rank, size);
    double run_time = MPI_Wtime() - start_time;

    if (rank == 0) {
        printf("Matrix multiplication completed in %f seconds\n", run_time);
    }

    MPI_Finalize();
    return 0;
}


**Q3**

#define SORT_SIZE 100
void odd_even_sort(int *arr, int n, int rank, int size) {
    int phase, i, temp;
    for (phase = 0; phase < n; phase++) {
        if (phase % 2 == 0) {
            for (i = 1; i < n; i += 2) {
                if (arr[i - 1] > arr[i]) {
                    temp = arr[i - 1];
                    arr[i - 1] = arr[i];
                    arr[i] = temp;
                }
            }
        } else {
            for (i = 1; i < n - 1; i += 2) {
                if (arr[i] > arr[i + 1]) {
                    temp = arr[i];
                    arr[i] = arr[i + 1];
                    arr[i + 1] = temp;
                }
            }
        }
        MPI_Barrier(MPI_COMM_WORLD);
    }
}


**Q4**

#include <mpi.h>
#include <stdio.h>
#include <stdlib.h>
#include <time.h>


#define GRID_SIZE 100
#define ITERATIONS 1000
#define TEMP_SOURCE 100.0
double grid[GRID_SIZE][GRID_SIZE];

void initialize_grid() {
    for (int i = 0; i < GRID_SIZE; i++) {
        for (int j = 0; j < GRID_SIZE; j++) {
            grid[i][j] = 0.0;
        }
    }
    for (int i = 0; i < GRID_SIZE; i++) {
        grid[0][i] = TEMP_SOURCE;
    }
}

void simulate_heat_distribution(int rank, int size) {
    int start_row = rank * (GRID_SIZE / size);
    int end_row = (rank == size - 1) ? GRID_SIZE : start_row + (GRID_SIZE / size);
    double new_grid[GRID_SIZE][GRID_SIZE];
    
    for (int iter = 0; iter < ITERATIONS; iter++) {
        for (int i = start_row; i < end_row; i++) {
            for (int j = 1; j < GRID_SIZE - 1; j++) {
                if (i > 0 && i < GRID_SIZE - 1) {
                    new_grid[i][j] = 0.25 * (grid[i - 1][j] + grid[i + 1][j] + grid[i][j - 1] + grid[i][j + 1]);
                }
            }
        }
        MPI_Allgather(&new_grid[start_row][0], (GRID_SIZE / size) * GRID_SIZE, MPI_DOUBLE, &grid[0][0], (GRID_SIZE / size) * GRID_SIZE, MPI_DOUBLE, MPI_COMM_WORLD);
    }
}

int main(int argc, char** argv) {
    MPI_Init(&argc, &argv);
    int rank, size;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);

    if (rank == 0) {
        initialize_grid();
    }
    MPI_Bcast(grid, GRID_SIZE * GRID_SIZE, MPI_DOUBLE, 0, MPI_COMM_WORLD);
    
    double start_time = MPI_Wtime();
    simulate_heat_distribution(rank, size);
    double run_time = MPI_Wtime() - start_time;

    if (rank == 0) {
        printf("Execution completed in %f seconds\n", run_time);
    }
    MPI_Finalize();
    return 0;
}


**Q5**


#include <mpi.h>
#include <stdio.h>
#include <stdlib.h>

// 5. Parallel Reduction using MPI

int main(int argc, char** argv) {
    MPI_Init(&argc, &argv);
    int rank, size;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);
    
    int local_value = rank + 1; // Each process gets a unique value
    int global_sum = 0;
    
    MPI_Reduce(&local_value, &global_sum, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);
    
    if (rank == 0) {
        printf("Total sum is: %d\n", global_sum);
    }
    
    MPI_Finalize();
    return 0;
}


**Q6**


#include <mpi.h>
#include <stdio.h>
#include <stdlib.h>



#define VECTOR_SIZE 100

int main(int argc, char** argv) {
    MPI_Init(&argc, &argv);
    int rank, size;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);
    
    int chunk_size = VECTOR_SIZE / size;
    double local_a[chunk_size], local_b[chunk_size];
    double local_dot = 0.0, global_dot = 0.0;
    
    
    for (int i = 0; i < chunk_size; i++) {
        local_a[i] = rank + i + 1; 
        local_b[i] = rank + i + 2;
        local_dot += local_a[i] * local_b[i];
    }
    
    MPI_Reduce(&local_dot, &global_dot, 1, MPI_DOUBLE, MPI_SUM, 0, MPI_COMM_WORLD);
    
    if (rank == 0) {
        printf("Dot product result: %f\n", global_dot);
    }
    
    MPI_Finalize();
    return 0;
}


**Q7**


#include <mpi.h>
#include <stdio.h>
#include <stdlib.h>


#define ARRAY_SIZE 100

int main(int argc, char** argv) {
    MPI_Init(&argc, &argv);
    int rank, size;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);
    
    int chunk_size = ARRAY_SIZE / size;
    int local_array[chunk_size], prefix_sum[chunk_size];
    int global_prefix = 0;
    
    for (int i = 0; i < chunk_size; i++) {
        local_array[i] = rank * chunk_size + i + 1;
    }
    
    MPI_Scan(local_array, prefix_sum, chunk_size, MPI_INT, MPI_SUM, MPI_COMM_WORLD);
    
    if (rank > 0) {
        int offset;
        MPI_Recv(&offset, 1, MPI_INT, rank - 1, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);
        for (int i = 0; i < chunk_size; i++) {
            prefix_sum[i] += offset;
        }
    }
    if (rank < size - 1) {
        MPI_Send(&prefix_sum[chunk_size - 1], 1, MPI_INT, rank + 1, 0, MPI_COMM_WORLD);
    }
    
    if (rank == 0) {
        printf("Prefix sum calculation completed.\n");
    }
    
    MPI_Finalize();
    return 0;
}


**Q8**

#include <mpi.h>
#include <stdio.h>
#include <stdlib.h>



#define N 4  

int main(int argc, char** argv) {
    MPI_Init(&argc, &argv);
    int rank, size;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);
    
    int local_matrix[N][N / size];
    int transposed_matrix[N][N / size];
    
    
    for (int i = 0; i < N; i++) {
        for (int j = 0; j < N / size; j++) {
            local_matrix[i][j] = rank * (N / size) + j + 1;
        }
    }
    
    MPI_Alltoall(local_matrix, N * N / size, MPI_INT,
                 transposed_matrix, N * N / size, MPI_INT, MPI_COMM_WORLD);
    
    if (rank == 0) {
        printf("Matrix transposition completed.\n");
    }
    
    MPI_Finalize();
    return 0;
}

